{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install pandas, numpy, scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install pandas`  \n",
    "`pip install numpy`  \n",
    "`pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataframe from list\n",
      "    name  math score  english score\n",
      "0  isaac          60             50\n",
      "1  julie          90             70\n",
      "2   alex          30             40\n",
      "create dataframe from dict\n",
      "    name  math score  english score\n",
      "0  isaac          60             50\n",
      "1  julie          90             70\n",
      "2   alex          30             40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_list = [('isaac', 60, 50),('julie', 90, 70),('alex', 30, 40)]\n",
    "header = ['name','math score','english score']\n",
    "df_from_list = pd.DataFrame.from_records(my_list, columns=header)\n",
    "\n",
    "print('create dataframe from list')\n",
    "print(df_from_list)\n",
    "\n",
    "\n",
    "\n",
    "my_dict = \\\n",
    "[{'name':'isaac', 'math score':60,'english score':50},\n",
    "{'name':'julie', 'math score':90,'english score':70},\n",
    "{'name':'alex', 'math score':30,'english score':40}\n",
    "]\n",
    "\n",
    "df_from_dict = pd.DataFrame(my_dict, columns=['name', 'math score', 'english score'])\n",
    "\n",
    "print('create dataframe from dict')\n",
    "print(df_from_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "0    1985      20   1228      81   1328      64    N      0\n",
      "1    1985      25   1106      77   1354      70    H      0\n",
      "2    1985      25   1112      63   1223      56    H      0\n",
      "3    1985      25   1165      70   1432      54    H      0\n",
      "4    1985      25   1192      86   1447      74    H      0\n",
      "        Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "145284    2016     132   1114      70   1419      50    N      0\n",
      "145285    2016     132   1163      72   1272      58    N      0\n",
      "145286    2016     132   1246      82   1401      77    N      1\n",
      "145287    2016     132   1277      66   1345      62    N      0\n",
      "145288    2016     132   1386      87   1433      74    N      0\n",
      "              Season         Daynum          Wteam         Wscore  \\\n",
      "count  145289.000000  145289.000000  145289.000000  145289.000000   \n",
      "mean     2001.574834      75.223816    1286.720646      76.600321   \n",
      "std         9.233342      33.287418     104.570275      12.173033   \n",
      "min      1985.000000       0.000000    1101.000000      34.000000   \n",
      "25%      1994.000000      47.000000    1198.000000      68.000000   \n",
      "50%      2002.000000      78.000000    1284.000000      76.000000   \n",
      "75%      2010.000000     103.000000    1379.000000      84.000000   \n",
      "max      2016.000000     132.000000    1464.000000     186.000000   \n",
      "\n",
      "               Lteam         Lscore          Numot  \n",
      "count  145289.000000  145289.000000  145289.000000  \n",
      "mean     1282.864064      64.497009       0.044387  \n",
      "std       104.829234      11.380625       0.247819  \n",
      "min      1101.000000      20.000000       0.000000  \n",
      "25%      1191.000000      57.000000       0.000000  \n",
      "50%      1280.000000      64.000000       0.000000  \n",
      "75%      1375.000000      72.000000       0.000000  \n",
      "max      1464.000000     150.000000       6.000000  \n",
      "Season    2016\n",
      "Daynum     132\n",
      "Wteam     1464\n",
      "Wscore     186\n",
      "Lteam     1464\n",
      "Lscore     150\n",
      "Wloc         N\n",
      "Numot        6\n",
      "dtype: object\n",
      "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "0    1985      25   1106      77   1354      70    H      0\n",
      "1    1985      25   1112      63   1223      56    H      0\n",
      "2    1985      25   1165      70   1432      54    H      0\n",
      "3    1985      25   1192      86   1447      74    H      0\n",
      "4    1985      25   1218      79   1337      78    H      0\n",
      "   Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "0      20   1228      81   1328      64    N      0\n",
      "1      25   1106      77   1354      70    H      0\n",
      "2      25   1112      63   1223      56    H      0\n",
      "3      25   1165      70   1432      54    H      0\n",
      "4      25   1192      86   1447      74    H      0\n"
     ]
    }
   ],
   "source": [
    "# use pandas to read csv file\n",
    "df = pd.read_csv('./dataset/RegularSeasonCompactResults.csv')\n",
    "\n",
    "# print first five row\n",
    "print(df.head())\n",
    "\n",
    "# print last five row\n",
    "print(df.tail())\n",
    "\n",
    "# statistics on the dataframe\n",
    "print(df.describe())\n",
    "\n",
    "# print max value of each column\n",
    "print(df.max())\n",
    "\n",
    "# print Wscore that is greater than 150\n",
    "df[df['Wscore'] > 150]\n",
    "\n",
    "# drop rows and reset index\n",
    "df_drop_row = df.drop(df.index[0])\n",
    "df_reset_index1 = df_drop_row.reset_index(drop=True)\n",
    "print(df_reset_index1.head())\n",
    "\n",
    "# drop columns\n",
    "df_drop_column = df.drop('Season', axis=1)\n",
    "print(df_drop_column.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  Daynum\n",
      "0    1985      20\n",
      "1    1985      25\n",
      "2    1985      25\n",
      "3    1985      25\n",
      "4    1985      25\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: Daynum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/RegularSeasonCompactResults.csv')\n",
    "\n",
    "# select two origin column as new dataframe\n",
    "df_new = df[['Season', 'Daynum']]\n",
    "print(df_new.head())\n",
    "\n",
    "# save dataframe to a csv file\n",
    "df_new.to_csv('dfnew.csv', index=False)\n",
    "#df_new.to_csv('dfnew.csv', index=False, header=False)\n",
    "\n",
    "# apply some logical operation to manipulate data\n",
    "df_daynum = df_new['Daynum'].apply(lambda x: 1 if x> 23 else 0)\n",
    "print(df_daynum.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3,)\n",
      "1 2 3\n",
      "[5 2 3]\n",
      "(2, 3)\n",
      "1 2 4\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[1. 1.]]\n",
      "[[7 7]\n",
      " [7 7]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0.13219466 0.58185592]\n",
      " [0.90149434 0.89322365]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])   # Create a rank 1 array\n",
    "print(type(a))            # Prints \"<class 'numpy.ndarray'>\"\n",
    "print(a.shape)            # Prints \"(3,)\"\n",
    "print(a[0], a[1], a[2])   # Prints \"1 2 3\"\n",
    "a[0] = 5                  # Change an element of the array\n",
    "print(a)                  # Prints \"[5, 2, 3]\"\n",
    "\n",
    "b = np.array([[1,2,3],[4,5,6]])    # Create a rank 2 array\n",
    "print(b.shape)                     # Prints \"(2, 3)\"\n",
    "print(b[0, 0], b[0, 1], b[1, 0])   # Prints \"1 2 4\"\n",
    "\n",
    "a = np.zeros((2,2))   # Create an array of all zeros\n",
    "print(a)              # Prints \"[[ 0.  0.]\n",
    "                      #          [ 0.  0.]]\"\n",
    "\n",
    "b = np.ones((1,2))    # Create an array of all ones\n",
    "print(b)              # Prints \"[[ 1.  1.]]\"\n",
    "\n",
    "c = np.full((2,2), 7)  # Create a constant array\n",
    "print(c)               # Prints \"[[ 7.  7.]\n",
    "                       #          [ 7.  7.]]\"\n",
    "\n",
    "d = np.eye(2)         # Create a 2x2 identity matrix\n",
    "print(d)              # Prints \"[[ 1.  0.]\n",
    "                      #          [ 0.  1.]]\"\n",
    "\n",
    "e = np.random.random((2,2))  # Create an array filled with random values\n",
    "print(e)                     # Might print \"[[ 0.91940167  0.08143941]\n",
    "                             #               [ 0.68744134  0.87236687]]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: http://cs231n.github.io/python-numpy-tutorial/#numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3   NaN          2.0          770        old\n",
      "4   NaN          NaN          870      young\n",
      "(5, 4)\n",
      "[ 3.  5.  2.  2. nan]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file\n",
    "df = pd.read_csv('./dataset/demo.csv')\n",
    "\n",
    "# load csv file without header\n",
    "#df = pd.read_csv('demo.csv', header=None)\n",
    "\n",
    "# print dataframe\n",
    "print(df)\n",
    "\n",
    "# print dataframe shape\n",
    "print(df.shape)\n",
    "\n",
    "# print column\n",
    "print(df['number_room'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin dataframe\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3   NaN          2.0          770        old\n",
      "4   NaN          NaN          870      young\n",
      "# of nan value in each columns:\n",
      "size           2\n",
      "number_room    1\n",
      "house_price    0\n",
      "house_type     0\n",
      "dtype: int64\n",
      "drop row that contain any missing value\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "fill missing value with mean\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3  34.0          2.0          770        old\n",
      "4  34.0          NaN          870      young\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file\n",
    "df = pd.read_csv('./dataset/demo.csv')\n",
    "\n",
    "print('origin dataframe')\n",
    "print(df)\n",
    "\n",
    "print('# of nan value in each columns:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print('drop row that contain any missing value')\n",
    "# drop row that contain any missing value\n",
    "df_no_missing = df.dropna()\n",
    "print(df_no_missing)\n",
    "\n",
    "print('fill missing value with mean')\n",
    "# fill missing value with mean \n",
    "df[\"size\"].fillna(df[\"size\"].mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin dataframe\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3   NaN          2.0          770        old\n",
      "4   NaN          NaN          870      young\n",
      "encode category\n",
      "   size  number_room  house_price  house_type\n",
      "0  40.0          3.0          800           0\n",
      "1  29.0          5.0          700           1\n",
      "2  33.0          2.0          670           1\n",
      "3   NaN          2.0          770           0\n",
      "4   NaN          NaN          870           1\n",
      "\n",
      "\n",
      "=============\n",
      "\n",
      "\n",
      "origin dataframe\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3   NaN          2.0          770        old\n",
      "4   NaN          NaN          870      young\n",
      "   size  number_room  house_price  house_type_old  house_type_young\n",
      "0  40.0          3.0          800               1                 0\n",
      "1  29.0          5.0          700               0                 1\n",
      "2  33.0          2.0          670               0                 1\n",
      "3   NaN          2.0          770               1                 0\n",
      "4   NaN          NaN          870               0                 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file\n",
    "df = pd.read_csv('./dataset/demo.csv')\n",
    "\n",
    "print('origin dataframe')\n",
    "print(df)\n",
    "\n",
    "print('encode category')\n",
    "df['house_type'] = pd.Categorical(df['house_type']).codes\n",
    "print(df)\n",
    "\n",
    "print('\\n\\n=============\\n\\n')\n",
    "\n",
    "df = pd.read_csv('./dataset/demo.csv')\n",
    "print('origin dataframe')\n",
    "print(df)\n",
    "df = pd.get_dummies(df)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change dataframe into numpy arrray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change dataframe to numpy array\n",
      "[[40.0 3.0 800 'old']\n",
      " [29.0 5.0 700 'young']\n",
      " [33.0 2.0 670 'young']\n",
      " [nan 2.0 770 'old']\n",
      " [nan nan 870 'young']]\n",
      "change numpy array to dataframe\n",
      "      0    1    2      3\n",
      "0  40.0  3.0  800    old\n",
      "1  29.0  5.0  700  young\n",
      "2  33.0  2.0  670  young\n",
      "3   NaN  2.0  770    old\n",
      "4   NaN  NaN  870  young\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# load csv file\n",
    "df = pd.read_csv('./dataset/demo.csv')\n",
    "\n",
    "print('change dataframe to numpy array')\n",
    "numpy_array = np.array(df)\n",
    "print(numpy_array)\n",
    "\n",
    "print('change numpy array to dataframe')\n",
    "df_from_numpy = pd.DataFrame(numpy_array)\n",
    "print(df_from_numpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before splitting......\n",
      "x: [[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]]\n",
      "\n",
      "y: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "shape of x: (10, 2)\n",
      "shape of y: (10,)\n",
      "\n",
      "after splitting......\n",
      "x_train: [[16 17]\n",
      " [18 19]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [14 15]\n",
      " [ 8  9]\n",
      " [10 11]]\n",
      "\n",
      "x_test: [[12 13]\n",
      " [ 2  3]\n",
      " [ 0  1]]\n",
      "\n",
      "y_train: [8 9 2 3 7 4 5]\n",
      "\n",
      "y_test: [6 1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = np.arange(20).reshape((10, 2)), np.arange(10)\n",
    "\n",
    "print('before splitting......')\n",
    "\n",
    "print(\"x: {}\\n\".format(x))\n",
    "print(\"y: {}\\n\".format(y))\n",
    "\n",
    "print(\"shape of x: {}\".format(x.shape))\n",
    "print(\"shape of y: {}\\n\".format(y.shape))\n",
    "\n",
    "# random_state = 1\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print('after splitting......')\n",
    "\n",
    "print(\"x_train: {}\\n\".format(x_train))\n",
    "print(\"x_test: {}\\n\".format(x_test))\n",
    "\n",
    "print(\"y_train: {}\\n\".format(y_train))\n",
    "print(\"y_test: {}\\n\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data into zero mean and unit std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of x_train: [4.00000000e+02 0.00000000e+00 3.33333333e-01]\n",
      "std of x_train: [355.9026084    0.81649658   1.24721913]\n",
      "\n",
      "mean of x_scale: [4.00000000e+02 0.00000000e+00 3.33333333e-01]\n",
      "std of x_scale: [355.9026084    0.81649658   1.24721913]\n",
      "\n",
      "after standardiztion......\n",
      "x_train: [[-0.84292723 -1.22474487  1.33630621]\n",
      " [ 1.40487872  0.         -0.26726124]\n",
      " [-0.56195149  1.22474487 -1.06904497]]\n",
      "apply same mean and std to new data(test data)\n",
      "\n",
      "x_test: [[-1.12671273  1.22474487 -0.26726124]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array([[ 100., -1.,  2.],\n",
    "                    [ 900.,  0.,  0.],\n",
    "                    [ 200.,  1., -1.]])\n",
    "\n",
    "\n",
    "print(\"mean of x_train: {}\".format(x_train.mean(axis=0)))\n",
    "print(\"std of x_train: {}\\n\".format(x_train.std(axis=0)))\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "print(\"mean of x_scale: {}\".format(scaler.mean_))\n",
    "print(\"std of x_scale: {}\\n\".format(scaler.scale_))\n",
    "\n",
    "# apply mean and std to standardize data\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "print(\"after standardiztion......\")\n",
    "print('x_train: {}'.format(x_train))\n",
    "\n",
    "\n",
    "x_test = np.array([[-1., 1., 0.]])\n",
    "print(\"apply same mean and std to new data(test data)\\n\")\n",
    "\n",
    "x_test = scaler.transform(x_test)\n",
    "print('x_test: {}'.format(x_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data into a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after standardiztion......\n",
      "x_train: [[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n",
      "apply same transformation to new data(test data)\n",
      "\n",
      "x_test: [[-1.5         0.          1.66666667]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "print(\"after standardiztion......\")\n",
    "print('x_train: {}'.format(x_train))\n",
    "\n",
    "\n",
    "x_test = np.array([[ -3., -1.,  4.]])\n",
    "print(\"apply same transformation to new data(test data)\\n\")\n",
    "\n",
    "x_test = scaler.transform(x_test)\n",
    "print('x_test: {}'.format(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.4\n",
      "r2 score: -0.6666666666666665\n",
      "number of correct sample: 3\n",
      "accuracy: 0.6\n",
      "confusion matrix: [[2 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "\n",
    "y_test = [0, 1, 0 , 1, 0]\n",
    "y_pred = [1, 0, 0 , 1, 0]\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "num_correct_samples = accuracy_score(y_test, y_pred, normalize=False)\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: {}\".format(mse))\n",
    "print('r2 score: {}'.format(r2))\n",
    "print('number of correct sample: {}'.format(num_correct_samples))\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('confusion matrix: {}'.format(con_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle website: https://www.kaggle.com/  \n",
    "kaggle api: https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
